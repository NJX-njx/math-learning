在上一个视频中， 您学习了学习率。 在机器学习中，学习率很重要 ，要找到一个好的学习率可能非常困难。 它也可能 对你的模型表现产生很大的影响。 假设你的学习率太大， 那么你可能会 因为步数太大而错过了最低限度，永远无法找到它。 如果学习率太小怎么办？ 好吧，你可能需要很长时间才能 真正达到最小值，或者可能永远无法达到最小值。 你想要的是恰到好处的学习率。 但是，要找到 恰到好处的学习率可能非常困难。 找到一个好的学习率实际上是一个研究问题。 有很多非常好的方法可以 根据问题的表现来改变学习率， 但是没有明确的方法 可以找到一个好的学习率。 现在，这是 梯度下降可能存在的另一个问题。 假设你这里有这个函数， 所以最小值实际上是这个函数。 但是，假设你开始 在这里运行梯度下降算法，好吧， 它永远不会让你达到最小值， 因为它会将你带到局部最小值， 指向最小值，看起来像最小值，但事实并非如此。 你是如何克服这个问题的？ 实际上没有安全的方法可以克服它。 但是要获得相当不错的结果，一种方法是 使用许多不同的起点多次运行梯度下降算法。 一旦你用这个运行它， 其中一个很可能会让你 达到最低限度，或者至少达到相当不错的地步。