欢迎来到第三周。 在本周中，你将学习什么是神经网络，以及 如何使用梯度下降来训练它们。 你还将学习一种制造异议的另一种方法，称为 牛顿方法，它也非常快速而且非常有用。 但让我们从第一个视频开始。 在本视频中， 您将学习神经网络的基本单元，即感知器。对@@ 你来说，这听起来像是一个陌生的术语，但你实际上已经看到一个已经准备就绪， 因为线性回归可以表示为感知器。 因此，让我们从回归问题背后的动机开始。 我们将使用线性回归中使用的最经典的例子之一， 根据房屋的大小来预测房屋的价格。 因此，假设你有三所房子的数据。 第一栋占地1000平方英尺，售价2万美元， 第二栋2000平方英尺，耗资3万美元， 第三栋房子面积为3000平方英尺，售价5万美元。 假设你在这张图表上绘制了更多的数据点。 因此，这些是市场上的其他房屋，其大小和价格。 目标是获取这些输入数据，也就是房子的大小， 在本例中找到一条线，因为它们看起来像形成了某种线条。 因此，我们将找到一条用来预测房屋价格的线。 目标是找到尽可能好的路线。 现在，在本例中，我们只有一种输入类型，这是 我们将用来保护价格的功能。 如果我们加入第二个功能会怎样？ 因此，让我们引入另一个功能，比方说房间的数量。 现在这些房子分别有2、4和7个房间。 有了这个新增功能，问题就不再那么简单了， 我们需要考虑这两个功能如何影响输出。 那么，我们如何建立和 训练一个能够预测房价等的模型。 如果我们有更多功能会怎样？ 它有什么 10 个功能或 100 个功能？ 好吧，这就是感知的用武之地。 因此，这个回归问题可以用单一的感知来建模。 这种感知将对我们 想要预测的一些未知输出进行一些输入。 因此，首先我们要从数学上探索感知开始。 因此，让我们从输入开始。 这里的输入将是x1和x2，对应于房屋的大小和 房间数量。 但我想让你想象一下，如果有 100 个输入， 那只是 100 个音符 x1 一直到 x100。 因此，我们从输入开始，然后将它们插入求和函数。 稍后我会详细解释这个问题。 求和函数中产生了 y hat 的输出，这将是我们预测的房屋价格。 因此，一个好的模型会得出相当不错的预测。 我们的想法是建立尽可能好的模型。 那么在这个求和步骤中发生了什么？ 让我来详细介绍一下。将@@ 这些特征 x1 和 x2 中的每一个都乘以相应的 权重，以确定它对输出的重要性。 因此，举个例子，如果房屋的大小 在预测房屋价格方面比房间数量重要 得多，那么这个权重将高于房间数量。 因此，让我们称相应的权重为 w1 和 w2。 为了组合这些权重和输入，我们只需将它们相加即可。 因此，我们将权重乘以 w1 乘以 要素 x1，然后将 w2 乘以 x2。 而且我们快到了。 我们还没有完全完成，因为还有一个偏差 项被添加到求和函数中。 现在我们添加这个，这就是输出。 在这个模型中，没有激活功能。 我稍后会告诉你什么时候有激活功能。 但是这里的输出只是 y hat，那是 w1x1 + w2x2 + b 作为房屋的预测价格。 目标是找到最佳 w1、w2 和 b 的权重和偏差，从而优化预测。 因此，当我们插入 x1 和 x2 时，那些会给我们带来最接近整个数据集实际价格的价格。 现在，我们该怎么做？ 我们如何找到这个完美的砝码？我们的@@ 想法是，我们想尽量减少某种错误。 错误基本上是你离房价有多远？ 因此，如果你最大限度地减少这个错误，那么这就是我们所需要的。 为此，我们引入了一种叫做损失函数的东西。 损失函数是一个小函数，它可以告诉我们， 我们距离很好地预测价格还有多远。 接下来的视频就是这样。