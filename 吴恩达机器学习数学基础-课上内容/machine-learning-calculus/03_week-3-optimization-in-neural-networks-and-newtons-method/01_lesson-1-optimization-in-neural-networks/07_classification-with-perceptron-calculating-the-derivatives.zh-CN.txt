现在我们知道问题出在哪里。 我们想计算 所有这些导数，并能够进行 梯度下降步骤，以便 为我们的数据集找到最佳的权重和偏差。 现在，让我们暂时关注体重 w_1。 这个想法是通过 使用 W1 四处移动来减少函数 L (y,)。 让我们先看看 w_1 是如何影响 L 的。 因为如果我们能找到向哪个方向移动 w_1 以便将 L 减小一点，那么 我们所需要做的就是多次 使用所有权重迭代这一步。 现在，在 L 和 w_1 之间有很多变量。 其中之一是 y Hat，因为 y Hat 会影响 L。我们需要 找出 L 相对于 y Hat 的偏导数。 现在，y hat 受到 w_1 的影响， 所以我们需要找出 y hat 被 w_1 的偏导数。 最后，这告诉我们 w_1 对 L 的影响有多大。 缺失的部分是 L 相对 w_1 的偏导数。 那才是我们真正想要找到的。 为什么？因为那告诉我们 w_1 对 L 有多大影响以及朝哪个方向影响。 这个是使用链式法则计算出来的。 Dia w_1 的 Dia L 是 Dia y Hat 的 Dia L t imes Dia y Hat 由 Dia W1 创作。 我们所要做的就是计算这两个， 以便通过直径W1计算Dia L。 W2 也会发生同样的情况。 我们想将W2改为左右以减少损失。 我们中间有这个隐藏的变量 y Hat。 我们想知道 y Hat 在多大程度上影响了损失。 我们还想知道 W2 在多大程度上影响 y Hat。 因此，我们将能够 在这里找到这个导数， Dia W2 的 Dia L ，它是 像以前一样使用链式法则计算的。 B. 也会发生同样的情况。 减少损失函数， 我们使用 Dia y hat 的 Dia L ，你已经计算过了。 这个受到 Dia B 的 B. Dia y Hat 的影响 ，它告诉我们 L 相对于 B 的导数。 用通常的链式法则再次找到这个。 我们有很多导数要计算 ，我要把它们放在这里。 第一个是 Dia B 的 Dia L ，我们使用链条规则编写， 然后是 Dia W1 的 Dia L 和 Dia W2 的 Dia L。 我们只有四件事要计算，因为 Dia y Hat 的 Dia L 经常出现。这些是什么？ 好吧，让我们回想一下，y Hat 是作为 在 W1 X1 加上 W2、X2 加 B 中获得的求和的 sigmoid 函数获得的。那么 l og loss 就是这个函数。 让我们开始计算事情吧。 首先，让我们来看看 Dia y Hat 的 Dia L， 这是最常出现的那个。 请注意，y Hat 的对数 与 y Hat 的导数为 1，而负 y 对于 y Hat 只是一个常数。 第一个项是减去 y 除以 y Hat。 最后，这就是我们将要拥有的。 原因是因为 第二个导数非常相似，一个减去 y 大于 一减去 y Hat，因为 分母中的 y 减去 y Hat 来自一减去 y Hat 的对数减去 y Hat。 当我们扩展它时， 这两个抵消了，我们得到的是 负 y 减去 y Hat over y Hat 乘以一减去 y Hat。 那是 Dia y Hat 的 Dia L。 我们将经常使用这个。 现在，让我们计算其他三个。 我们如何计算 Dia W1 的 y Hat？ 好吧，请记住，sigmoid 的导数 是 sigmoid 乘以一减去 sigmoid。 这将是内部的 sigmoid 乘以内部部分向上减去 sigmoid， 这与 y Hat 相同，乘以 一减去 y Hat 乘以 X1， 这是内部乘以 W1 的导数。 出于同样的原因， Dia W2 的 Dia y Hat 是这个，dia B 的 Dia y Hat 是 y Hat 乘以一减去 y Hat。 回想一下，这是利用这样 一个事实，即 某物的 sigmoid 的导数是 sigmoid 乘以一减去 sigmoid。 这就是 y Hat 乘以 y 减去 y Hat 的用武之地。 现在我们计算了一堆导数。 我们所需要做的就是将它们相乘。 Dia B 的 Dia L 是什么？ 好吧，是 Dia y Hat 的 Dia L，就是这样， 时代是 Dia B 的 Dia y Hat 就是这样。 我们对 Dia W1 的 Dia L 所做的事情也是如此。 这是 Dia y Hat 的 Dia L times Dia y Hat by Dia W1。 最后，W2 也是如此。 这是 Dia y Hat 上常见的 Dia L times Dia y Hat by Dia W2。 现在我们需要取消一大堆东西。 请注意，这两个 抵消了 y Hat 减去 y Hat， 抵消了分母和分子。 我们最终得到了一些非常不错的衍生品。 来看看吧。 Dia B 的 Dia L 只是负数 y 减去 y Hat。 Dia W1 的 Dia L 为负 y 减去 y Hat 乘以 X1。 Dia W2 的 Dia L 为负 y 减去 y Hat 乘以 X2。 请注意，如果 y 和 y Hat 非常接近 ，则这些区域非常小， 这意味着您无需进行太多 更改，因为您已经有了很好的预测。 但是，如果你有一个错误的预测，那 么 y 和 y Hat 彼此相距甚远。 因此，你需要一个很大的 导数来移动很多东西。 让我们回到原来的样子。 我们的主要目标是找出 W1、 W2 和偏差 B 的最佳值。 我们可以使用偏导数表达式。 我们发现梯度下降表达式如下。 这里是 set，这里是 set 的 sigmoid， 输出介于 1 和零之间。 对数损失为 L (y,)。 你猜对了，为了找到 W1、W2 和 B 的最佳值，我们将使用梯度下降。 这是 W1 的更新步骤。 现在请注意，我们已经知道 了L相对于W1的偏导数， 而这正是这样。 这与 W2 的步骤类似。 我们也可以用 我们已经发现的东西代替衍生物。 这是替换 B 的步骤。 同样，我们可以放出我们所知道的导数。 换句话说，这是更新步骤。 你从一些 W1、 W2 和 B 开始， 然后使用这个过程进行迭代。 如果你多次这样做， 你就会得到一些相当不错的 W1、 W2 和 B 值。 我会给你一个非常好的模型 ，它可以很好地映射你的数据集。 那就是分类主体的梯度下降。