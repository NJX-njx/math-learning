在前面的视频中，您学习了二阶导数 以及它在优化问题中的用处。 所有这些都集中在一个变量中。 接下来，我将向你展示它 在多个变量中的工作原理。 对于多个变量， 二阶导数实际上是一个 充满二阶导数的矩阵，称为黑森矩阵。 现在我将向你展示黑森算法、 它的属性以及它在优化中的用法。 特别是，当我们想要 优化由 多个变量组成的函数时，我们可以使用多变量牛顿方法，而该方法使用黑森法。 让我们先对一个变量 和两个变量的函数进行一些比较。 回想一下，一个变量的函数被称为 x 的 f， 它只依赖于变量 x， 而两个变量的函数则 取决于变量 x 和 y。 一阶导数只是 f 素数 x，它 是 f 相 对于唯一变量 x 的变化率。 当你有两个变量时， 你有两个变化率。 f 相对于 x 的变化率称为 f_x， f 相对于 y 的变化率叫做 f_y。 如果将它们放在一起，就会得到梯度 nabla f，这是一个向量。 现在二阶导数会发生什么？ 一个变量的二阶导数有 x 素数。 这就是 效应变化率的变化率。 对于两个变量，好吧， 让我们看看会有什么。 这就是我要在这段视频中向你展示的内容。 为了理解两个变量的二阶导数， 让我们分析一下这个简单示例 f of x， y) 等于 2x 平方加上 3y 平方减去 xy。 我们可以取相对 x 的导数， 即 4x 减去 y， 对于 y 的导数， 即 6y 减去 x。 现在我们可以取二阶导数。 我们可以取与 x 相关的导数，即 4。 我们可以取 4x减去y对y的导数 ，那就是负1。 对于第二个，6y 减去 x， 我们可以取相对 x 和 y 的导数， 然后得到负 1 和 6。 这四个是变化率的变化率。 这是 f_x 对 x 的变化率，f_x 相对 y 的变化率， 然后是 f_y 相对 x 的变化率，f_y 相对 y 的变化率。注意一些 奇怪的东西。 这两个是一回事。 这种情况几乎无时无刻不在发生， 但让我们来总结一下。 前两个是相 对于x的变化率，然后是相对于x的变化率， 还有对y的变化率以及对y的变化率。 它们的工作原 理与一个变量完全一样，因为如果你把f当作只有x的函数， 你可以取x的f素数， y的素数也一样。 但是，最后两个有点奇怪。 这是沿 一个坐标轴的斜率与沿 正交坐标轴的微小变化而发生的变化。 在大多数情况下，这两者实际上是相同的。 你需要两个偏导数才是可微分的。 当两个偏导数均可微分时， 导数相对于 y的导数与导数相对于x的导 数与导数相对于 x的导数相同。 在莱布尼兹的表示法中，我们可以 将其写成d平方 f 大于 dx 平方，d 平方 x 大于 dy 平方。 对于另外两个，d 平方 f 比 dxdy 和 d 平方 f 而不是 dydx。 拉格朗日表示法，我们得到 f_xx、f_yy、 f_xy 和 f_yx。 现在，让我来告诉你什么是黑森矩阵。 让我们回到 这里的这张小图，我们取了 x 和 y 的导数， 然后是相对于 其中每个 x 和 y 的偏导数。 当我们把这四个放在一个矩阵中时， 我们得到的是黑森矩阵。 这里的黑森矩阵是 4， 负 1，负 1，6。 黑森矩阵为我们提供了 很多关于二阶导数的信息。 正如我们很快就会看到的那样，它在优化中也非常有用。 在一般情况下，我们有函数 f， 即偏导数 f_x 和 f_y。 它们是偏导数 f_xx、f_xy、f_yx 和 f_yy。 当我们把它们放在一个矩阵中时， 我们得到的就是像以前一样的黑森矩阵。 正如我之前提到的， 这个黑森矩阵中有很多信息。 现在让我们回到我们的桌子上。 在我们的表中，我们知道 一个变量的二阶导数只是 x 的 f 素数。 两个变量中的素数是什么？是黑森人。 它是跟踪 所有二阶偏导数的矩阵。