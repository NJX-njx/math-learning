在本视频和以下视频中，我将向你展示一种替代 下降分级的方法，称为牛顿方法。 牛顿的方法也非常快速且非常强大， 原则上使用牛顿的方法来求函数的零。 但是，我们可以对其进行一些调整以用于优化。 牛顿的方法也适用于许多变量，但 让我们先来看看它在一个变量中的工作原理。 因此，假设你在这里有这个函数，你的目标是找到零。 所以在这里找到这个点，那就是 X 的 F 等于零的地方。 因此，这里有一种很好的方法可以很好地近似这个零，其 作用类似于对下降进行分级。 让我们从一些随机点 X 零开始，那不是函数的零， 但没关系，我们将从这里得到一个更好的点。 让我们来看一下此时的切线，所以让我们取导数然后 画出切线，看看它与水平 X 轴的位置。 此时我们要称之 为 X1，请注意 X1 比 X0 更接近零。 所以我们需要做的就是在这里迭代，所以让我们再做一次。 绘制导数并找到一个新点 X2， 注意 X2 与函数的零点有多接近。 所以我们差不多到了第三点，那里非常接近零。 所以我们差不多找到了，我们没有完全找到它，但我们已经接近了。 这就是重点，为了能够近似零， 这个函数非常好。 现在让我们添加一些数字，这条线的斜率 F 素数为 X0。 这里的高度是 X0 的 F， 底数是 X0 减去 X1。 因此，这里的斜率公式是，在 运行中上升，现在上升 FX0，跑步是 X0 减去 X1， 因此 X0 的 F 素数等于 FX0 除以 0 减去 X1。 我们可以对其进行操纵以得出 X1 等于 X 0 减去 X0 的 F 除以 X0 的 F 素数。 这就是迭代步骤，你有 F 为零， 你只需基于 X0 计算 X1 然后迭代，那么我们该如何迭代呢？ 好吧，让我们再走一步， 假设你已经完成了 K 次而且有 2XK。 这里的斜率是 XK 的 F 素数，这个高度是 XK 的 F， 这个水平距离 XK 减去 XK 加 1。 因此，在转义加一之前使用相同的方法 等于 X K 减去 FXK 除以 XK 的素数。 既然你知道，XK，你知道 F，你知道导数， 那么你可以找到 XK plus 1。 所以你在步骤上迭代然后得到牛顿的方法，现在的问题是， 你如何用它进行优化？ 因为请记住，梯度下降找到了函数的最小值，所以 牛顿的方法只是找到函数的零，而不是最小值。 好吧，我们只记得，当你想最小化 X 的函数 G 时， 你实际上必须找到 X 的 G 素数的零。 因此，如果我能找到一个函数的零，我就快要最小化它了。 我只需要查看所有的零， 看看哪些是最小值，因为这些是最小值的候选值。 所以换句话说，如果我让 X 的 F 成为 X 的 G 的导数， 那么通过找出 X 的 F 的零，我就最小化了 X 的 G 素 数。而 X 的 F 素数的导数，只是 X 的 G 的导 数及其导数。 所以换句话说，这里是算法，对于 牛顿的方法，我们从一些X0开始。 现在，如果我想找到 F 的零，我所要做的就是更新， 步骤是 XK 加 1 是 XK 减去 XK 的 F 而不是 XK 的 F，而不是 XK 的 F 素数， 其中 XK 是我的 K 迭代，XK 加 1 是我的 K 加 1 迭代。 现在在牛顿的优化方法中， 除了不是用 F，而是用 G 素数之外，我必须做同样的事情，所以我有 XK 加 1。 K 加 1 迭代是 XK 减去 XK 的 G 素数，再 除以 XK 素数（二阶导数）的 G 素数。 因此，这很快就会成为一件大事，但在此之前， 让我们进行迭代步骤。 迭代步骤是重复 2，直到找到根，左边和 右边是重复 2，直到找到最小值。