欢迎参加 机器学习和数据科学数学专业的第二门课程。 在第二门课程中，您将学习微积分。 那么衍生物，这是什么意思，它是如何工作的，它 在机器学习中是如何使用的？ 您还可以学习一些高级技术，例如牛顿方法。 我很高兴 路易斯·塞拉诺再次担任这门课程的讲师。 >> 非常感谢。 是的，我对这门课程感到非常兴奋。 机器学习有很多最小化和最大化函数 的方法，这就是本课程的主要应用。 为此，我们使用衍生品。 >> 事实上，我们在机器学习中所做的几乎所有事情。 因此，我们在机器学习中所做的很大一部分是创建一个成本函数， 然后将其最小化。 那就是微积分。 >> 没错。当你想训练机器学习 模型时，你可以计算出错误有多糟糕，然后尽量减少错误。 因此，为此，我们使用导数，我们使用梯度， 我们教他们很多技巧。 >> 是的，经常有几行代码实现梯度下降 或其他实际使用微积分的算法，以至 于有人推导出导数然后在代码中实现它。 因此，理解这一点似乎 是对普通人的表现有良好直觉的核心。 >> 当然，是的。 如果你想了解这些优化器是如何工作的 ，它们通常会看黑匣子，如果你想了解它们， 最好知道背后的微积分。 归根结底，你只是在一步一步地做点什么。 >> 对。>> 因为梯度下降只是花了 很小的步骤来获得越来越低的值。 你朝哪个方向迈出这一步？ 好吧，渐变可以准确地告诉你方向。 >> 因此，对于 第一次学习这篇文章的人来说，有时候看起来很神秘的一件事是，当你想到一维或 二维的导数时，就像斜率一样。 但是在机器学习中，我们经常以非常、非常高的维度进行导数， 比如 10,000 或 100 万维空间真的很难可视化。 因此，在本课程中，你还可以让人们直觉这些 非常高的维度空间中正在发生的事情。 当你在这些非常高的维度空间中进行微积分时。 >> 绝对可以。 因此，就像你在第一课中看到的那样，数据可以是非常高的维度。 当你谈论衍生品时，它可能有许多方向。 这些是由长向量和长矩阵捕获的。 所以我们甚至选择二阶导数。 二阶导数会根据 二阶导数得出的矩阵告诉你空间的曲率是多少。 >> 而且导数是导数。 这也导致了牛顿的方法。 >> 是的，Newton 的方法是一种非常酷的方法，可以最小化函数。 因此，梯度下降实际上效果很好。 但是很多时候，梯度下降可能需要数百个步骤，而 牛顿的方法可能只需要几个步骤就能得到相同的结果。 >> 是的。不适用于所有应用程序。 很多参数不多。 但是当它起作用时，它的速度可能非常快。 >> 是的。这个想法是 让你拥有一个包含不同技术的工具包。 如果这个行得通，那就太棒了。 但如果没有，你可以试试这个或那个，或者那个。 我们在机器学习中就是这样做的，对吧？ >> 实际上，就两个孩子而言，这个 专业最酷的地方之一也是所有的笔记本电脑，所有的实验室。 >> 绝对可以。 因此，就像上一门课程一样，你将能够 在很多代码实验室中实时看到这些概念的运行情况。 >> 因此，在本课程中，您将学习概念，运行代码实验室 ，甚至希望获得可以在自己的项目中使用的代码片段。 因此，我很高兴你能深入学习第二门课程， 开始学习这些重要的微积分概念。 因此，请继续观看下一个视频。