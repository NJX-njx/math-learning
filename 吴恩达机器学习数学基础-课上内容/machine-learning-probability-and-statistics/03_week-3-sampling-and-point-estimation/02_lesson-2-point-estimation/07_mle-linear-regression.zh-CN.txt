回想一下， 在机器学习中使用最大可能性的方法如下。 我们有一堆数据和 一些可能的模型可以生成这些数据。 对于每个模型， 您可以 根据模型 1、模型 2 和模型 3 计算数据出现的概率。 给出 最高概率的人是赢家， 这意味着你会找到 最有可能在这些数据中生成的模型。 概率最高的人是赢家， 也就是给定模型中数据 P 最大化的那个。 这里有一个线性回归的小例子。 假设这些是 你的观点，你正在努力为它们画一条线， 但我们不要试图为它们画一条线。 让我们试着抓住概率去做。 候选人是模型 1，这是这条线， 模型 2 是这条线 ，模型 3 是这条线。 首先，让我们想一想， 哪一个看起来最合适？ 最合适的将是 给出最高概率的那个。 第一个生成具有一定概率的数据， 第二个生成概率更高的数据， 第三个生成概率为中等概率的数据。 赢的就是这个。 但是，我还没有告诉 你一条线是如何生成点的。 接下来让我告诉你。 这个想法是让 这些线生成靠近直线的点。 把它想象成一条路。 如果你把那条路当成 黄线然后你开始建造房屋，那么 房屋很 可能会建在离道路不远的地方。这@@ 条路是 Model 2 那么房屋很可能在这些 地方，如果道路是 Model 3，那么房屋很可能就在这里。 但是，让我在这里输入一些数字。 假设这是你的模型，这是点 x ，线点在这里。 您将 使用高斯生成一个靠近直线的点。 我们放一个高斯值， 然后将其居中放置在直线与 水平线交汇处。 我们要从那个高斯中取样， 所以我们在这里对这个进行采样。 也 就是说，我们要建造一座可能离 道路很近的房子，然后 从那边的垂直高斯中取样， 如果我们有一堆点 x_1 到 x_5， 那么我们就有五个高斯值都以蓝线上的点为中心。 从其中的每一个中， 我们都要采样一些观点。这是@@ 我们 根据这条蓝线采样的五个点。 现在，我们所要做的就是找到 最能生成点的线， 最有可能产生这些点的线。 巧合的是，这将是线 性回归线的最佳拟合。 为什么会这样？ 好吧，让我们做一些数学运算。 假设直线的方程为 y = mx+b， 这些是与 直线的交点，这些是生成的点。 这些距离将被称为 d_1、d_2、d_3、d_4 和 d_5。 首先，让我们计算 生成此点的可能性。 既然我们有高斯值， 那么真正发生的事情是 高斯以 x_1 与那条蓝线相交的点为中心， 我们在这里生成另一个点。 如果我们假设它是 标准差 1 且均值等于 0 的高斯值， 则生成这些点的可能性 由高 斯公式给出，即 2Pi 的 1/平方根 (e^-1/2d_1^2)。 这就是耗尽第一点的可能性。 我们正在研究所有这些。 这是五种可能性的乘积。 这就是我们必须最大限度地发挥作用的。 我们必须最大限度 地提高直线生成所有这些点的可能性。 既然它们是独立的， 那么我们必须看看产品。 这些东西中有很多是常数。 这个 1/平方根 2Pi。 让我们忘记它们 ，让我们在这里最大限度地提高这一点。 我们可以将其分解为 e^-1/2 乘以 d 高度的平方和。 请注意，如果我们最大化某物，则与 最大化 对数相同，这样我们就可以摆脱这个 e， 也可以去除 1/2， 因为那只会乘以 2。 但是，让我们记住这里有一个负数。 这意味着我们必须最小化平方和。 最小化 平方和正是最小二乘误差。 这正是线性回归的本质。 在线性回归中， 您需要找到 最小化与该点的平方距离之和的蓝线。 这表明， 使用 最大似然法找到最有可能产生点的线与 使用线性回归最小化最小二乘误差完全相同。 以下是三个示例，说明 线和每个点都会退化的高斯函数。 如你所见， 当我们计算 蓝点的实际数据集的概率时， 获胜的就是中间的那个， 我们可以看到这是最适合该数据集的线。