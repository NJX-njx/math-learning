在本视频中，您将学习 最大似然估计（MLE）。 MLE 在机器学习中被广泛用于训练模型， 但是 MLE 背后的概念非常简单。 想象一下，你有一些证据证明 某件事，你想找到 可能导致这些证据的情景， 这样你就可以从所有可能的情景中挑选出来， 即创造 可能性最高的证据的情景。 让我举个例子来给你看。 想象一下，你走进 客厅，看到一堆 爆米花躺在沙发旁边的地板上。 这里有一个问题要问你。 其中哪一个事件 更有可能发生？ 人们在看电影， 人们在玩棋盘游戏， 或者有人在小睡。 你认为哪一个更有可能发生？ 好吧，让我们试着看看是什么原因导致了 爆米花的概率最高。 看完电影后爆米花掉在地板上的可能性很高。 对于棋盘游戏来说，它是中等的，对于小睡一会来说， 它很低，因为小睡 不会在地板上产生爆米花。 因此，我们将选择任何创造 爆米花的概率更高的东西，那就是电影。 因此，我们将推断， 最有可能发生的事情 是人们在看电影。 我们所做的就是最大限度地提高 条件概率，因为 给定电影的爆米花概率很高， 然后 是棋盘游戏中爆米花的概率，中等 ，小睡一会爆米花的概率很低。 因此，我们找到了最高的条件概率。 换句话说，我们所 做的就是找到最 有可能导致地板上爆米花的场景。 这称为最大可能性。 我们选择了 更有可能获得证据的情景。 这实际上是 机器学习中多次做的事情。 你有一堆数据和 几个模型可以生成这些数据。 你要做的就是估计 给定模型 1 我们看到这些数据的概率。 在给定 模型 2 和给定模型 3 的情况下，我们看到 这些数据的概率是我们选择的模型， 即最有可能生成数据的模型。 换句话说，我们正在最大限度地提高 给定模型的数据概率。 现在为什么线性回归适合这里呢？ 稍后我们将详细介绍。 但是，为了给你一个模糊的想法 ，想象一下你把它当作你的数据点 和三个可能的模型 ，想象一下我们有一种方法可以 根据一条线生成 点，而这些点将在靠近直线的地方生成。 因此，这些 点很可能基于模型 1、 基于模型 2 和模型 3 出现，给出这些 点的概率最高 的模型就是我们要选择的模型。 但是，再说一遍，我们稍后会详细介绍。