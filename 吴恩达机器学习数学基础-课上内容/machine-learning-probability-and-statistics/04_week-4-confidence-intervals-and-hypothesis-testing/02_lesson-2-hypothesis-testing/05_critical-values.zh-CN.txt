到目前为止，您将学会根据 观测到的统计量的 p 值做出决策。 如果 p 值小 于显著水平 Alpha， 则您拒绝原假设并 接受备选假设为真。 你可以问自己的一件事是，你 能 得到的最极端的样本是什么，这样你仍然会拒绝 H_0。 此样本的 p 值正好为 Alpha。 任何不如该样本极端的样本都无法 满足 p 值小于 Alpha 的条件。 这称为临界值。 请注意，这取决于 您为 Alpha 选择的值。 不同的 Alpha 决定了不同的临界值。 临界值通常被称为 K Alpha，以强调这种依赖性。 关于临界值的一个很酷的事情是， 任何 比临界值更极端的观测统计量的 p 值将始终为 Alpha 或更低。 您可以 根据临界值创建决策规则。 让我们再次回到 关于18岁平均身高的右尾测试示例。 假设总体均值为 66.7， H_1 假设总体均值大于 66.7。 在本示例中，您使用的 样本量为 n 等于 10，而总体标准差为 sigma 等于 3。 假设你对 0.05 的 Alpha 值感兴趣。 你需要找出 K 的值， 0.05，它的 p 值 正好等于 Alpha 等于 0.05。 但这只不过是 向右留出0.05区域的值， 这意味着临界值只 不过是分位数1-0.05。 现在，当总体均值的值为 66.7（对应于原假设）时， 样本均值为均值 66.7 的高斯分布和三除以根 10 的标准差。 对于此分布，临界值为 68.26。 既然你已经有了临界值， 就可以制定决策规则了。 如果 观测到的样本均值大于 68.26，则可以否定 H_0。 关于 临界值的一个很酷的事情是，你可以在 收集任何数据之前定义自己的决策规则。 获得数据后， 您可以计算观测到的统计数据 并据此做出决定。 在我们的示例中，观测到的样本均值为 68.442，大于临界值 68.26。 在此示例中，当 显著性水平为 0.05 时，您将否定原假设。 这与 您在使用 p 值方法时得出的结论完全相同。 现在，如果你把 Alpha 改成 0.01 会发生什么？ 好吧，由于 0.01 小于 0.05， 那么 K，0.01 肯定会让你向右移动。 这意味着你需要更多针对 H_0 的证据才能驳回 它。临界值将是 68.91。 现在， 如果观测到的样本均值大于 68.91，则决策规则将是否定原假设。对于@@ 您的数据， 这意味着您不能拒绝 显著性水平为 0.01 的原假设。 现在让我们看看 每种测试的临界值是什么样子。 对于右尾检验， K Alpha 是在 原假设下位于右边的 Alpha 区域的值。 这意味着，当零为 真时，临界值为一个方块，一个减去统计分布的 Alpha 值。 如果 观测到的统计量 T 大于临界值，则决策规则被拒绝为零。 对于左尾检验， 临界值将是 向左留出 Alpha 区域，使其 与分位数 Alpha 相对应的临界值。 在这种情况下，决策规则是， 如果观测到的统计 量小于临界值，则否定原假设，最后， 我们得到双尾检验。 在这种情况下，需要在 分布的两条尾部之间划分误差概率。 这意味着你需要找到 两个临界值 K Alpha 一个在右边留出一个区域 Alpha 2， K Alpha 2 在 左边看上去是 Alpha 2 的区域。 它们 分别对应于两个分位数上的一个减去 Alpha 和两个分位数上的 Alpha。 如果 观测到的统计量大于 K Alpha 1 或小于 K Alpha 2，则不会拒绝 H)。 为了总结临界值， 我们可以 提前定义临界值，因为你不需要样本就能得到临界值， 你只需要知道设计条件，例如 样本量以及你 可能需要 的有关所研究人群分布的任何信息。 P值法和 临界值法必须 始终引导您得出相同的结论，这一点非常重要。 正如我们提到的，对于临界值， 您可以事先定义决策标准， 然后在获得数据后做出决定。 这使得 确定类型 2 的误差概率成为可能。 由于您有明确的决策规则 ，该规则不依赖于观测结果， 因此您可以很容易地发现出现 2 型错误的可能性。 您将在以下视频中详细了解它。