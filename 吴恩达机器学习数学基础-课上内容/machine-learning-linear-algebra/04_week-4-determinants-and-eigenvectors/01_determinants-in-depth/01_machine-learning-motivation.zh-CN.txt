欢迎来到第 4 周。 本周你将继续 通过线性变换的 视角学习线性代数中一些最重要的概念。 首先，您将看到一些概念，例如 行列式和奇点，对线性变换意味着什么 。 你会很高兴看到它们看起来多么自然。 然后，您将学习 线性代数在现实世界中最强大的应用之一 ，即特征值和特征向量。 它们被广泛用于许多领域， 包括机器学习，特别是在 一种非常重要的 降维算法中，称为 主成分分析或 PCA。 我喜欢将 PCA 想象成对你的数据进行拍照。 假设你正在参观 旧金山最受欢迎的旅游景点之一，彩绘的树叶。 这个景点主要是一系列 俯瞰大海的老房子，上面涂有 不同的颜色，因此得名。 你拿出相机，目标是 尽可能多地捕捉风景。 因此，你想在照片 中尽可能多地拍摄建筑物。 为此，您需要尝试一系列 不同的姿势来捕捉完美的镜头。 完美的镜头是什么？是从前面拍的。 你不想从 旁边拿一个然后错过美景。 还要注意，当你拍照时， 你会将房屋从 三维物体简化为二维物体。 你仍然设法 尽可能多地捕捉到它们上的信息。 同样，当你有一个 非常高的维度数据集时， 有一种方法可以将其转化为更简单、维 度更少的数据集，同时还 能尽可能多地捕获数据集的信息。 PCA 就是这样做的。 它会对您的数据进行拍照，并 尝试捕获尽可能多的信息。 以下是PCA会做什么的示例。 想象一下，这些点构成了 你的数据集，你想简化 B 的数据集。 例如，尽管这些点在太空中， 但 它们中的大多数似乎都靠近这条线。 也许我们可以 从直线的角度来看数据集。 这就是PCA要做的。 你会找到这条线 ，然后从直线的角度来看数据集。 换句话说，它将把 所有点投射到直线上。 这就是变换数据集。 请注意，丢失了一点信息 ，但没有丢失太多。 我们仍然可以非常真实地了解数据。 然后我们从二维变为一维。 这就是为什么这种算法 被称为降维算法。 现在，PCA 比简单地将 二维画面变成一维画面要强大得多。 想象一下，你有一个包含 很多列的数据电子表格，比如八列。 PCA 可以识别 数据集和列中是否存在冗余 ，也许可以将其概括为 三列，而不会丢失太多信息。 在这种情况下，PCA 会将数据 集的维度从八维降至三维。 这将使存储 、操作和构建良好的机器学习模型变得更加容易。 PCA 是如何运作的？ 它适用于特征值和特征向量。 在资源中，你可以找到一些视频 和材料的链接，这些链接可以更详细地解释它。